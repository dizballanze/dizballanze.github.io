<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Tech blog by @dizballanze - Yuri Shikanov</title><link href="/ru/" rel="alternate"></link><link href="http://dizballanze.com/feeds/yuri-shikanov.atom.xml" rel="self"></link><id>/ru/</id><updated>2017-06-27T16:00:00+03:00</updated><entry><title>Оптимизация производительности Django проектов (часть 2)</title><link href="/ru/django-project-optimization-part-2/" rel="alternate"></link><published>2017-06-27T16:00:00+03:00</published><updated>2017-06-27T16:00:00+03:00</updated><author><name>Yuri Shikanov</name></author><id>tag:None,2017-06-27:/ru/django-project-optimization-part-2/</id><summary type="html">&lt;p&gt;Содержание:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#massovye-izmeneniia"&gt;Массовые изменения&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#massovaia-vstavka"&gt;Массовая вставка&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovaia-vstavka-m2m"&gt;Массовая вставка M2M&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovoe-izmenenie"&gt;Массовое изменение&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovoe-udalenie-obektov"&gt;Массовое удаление объектов&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#iterator_1"&gt;Iterator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ispolzovanie-vneshnikh-kliuchei"&gt;Использование внешних ключей&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#poluchenie-sviazannykh-obektov"&gt;Получение связанных объектов&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ogranichenie-polei-v-vyborkakh"&gt;Ограничение полей в выборках&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#indeksy-bd"&gt;Индексы БД&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lenqs-vs-qscount"&gt;len(qs) vs qs.count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#count-vs-exists"&gt;count vs exists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lenivyi-queryset"&gt;Ленивый QuerySet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Это продолжение серии статей про оптимизацию Django приложений. Первая часть доступна
&lt;a href="/ru/django-project-optimization-part-1/"&gt;здесь&lt;/a&gt; и рассказывает …&lt;/p&gt;</summary><content type="html">&lt;p&gt;Содержание:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="#massovye-izmeneniia"&gt;Массовые изменения&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href="#massovaia-vstavka"&gt;Массовая вставка&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovaia-vstavka-m2m"&gt;Массовая вставка M2M&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovoe-izmenenie"&gt;Массовое изменение&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#massovoe-udalenie-obektov"&gt;Массовое удаление объектов&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="#iterator_1"&gt;Iterator&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ispolzovanie-vneshnikh-kliuchei"&gt;Использование внешних ключей&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#poluchenie-sviazannykh-obektov"&gt;Получение связанных объектов&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#ogranichenie-polei-v-vyborkakh"&gt;Ограничение полей в выборках&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#indeksy-bd"&gt;Индексы БД&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lenqs-vs-qscount"&gt;len(qs) vs qs.count&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#count-vs-exists"&gt;count vs exists&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="#lenivyi-queryset"&gt;Ленивый QuerySet&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Это продолжение серии статей про оптимизацию Django приложений. Первая часть доступна
&lt;a href="/ru/django-project-optimization-part-1/"&gt;здесь&lt;/a&gt; и рассказывает о профилировании и настройках Django. В этой части
мы рассмотрим оптимизацию работы с БД (модели Django).&lt;/p&gt;
&lt;p&gt;В этой части часто будет использоваться логирование SQL запросов и DDT, про которые написано в первом посте.
В качестве БД во всех примерах будет использоваться PostgreSQL, но для пользователей других СУБД большая часть статьи
также будет актуальна.&lt;/p&gt;
&lt;p&gt;Примеры в этой части будут основаны на простом приложении блога, которое мы будем разрабатывать и оптимизировать по
ходу статьи. Начнем с следующих моделей:&lt;/p&gt;
&lt;p&gt;```python
from django.db import models&lt;/p&gt;
&lt;p&gt;class Tag(models.Model):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;name = models.CharField(max_length=64)

def __str__(self):
    return self.name
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;class Author(models.Model):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;username = models.CharField(max_length=64)
email = models.EmailField()
bio = models.TextField()

def __str__(self):
    return self.username
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;class Article(models.Model):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;title = models.CharField(max_length=64)
content = models.TextField()
created_at = models.DateField()
author = models.ForeignKey(Author)
tags = models.ManyToManyField(Tag)

def __str__(self):
    return self.title
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Весь код доступен на &lt;a href="https://github.com/dizballanze/django-optimization-guide-2-sample/tree/initial"&gt;GitHub&lt;/a&gt;
с разбивкой по &lt;a href="https://github.com/dizballanze/django-optimization-guide-2-sample/tags"&gt;тегам&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="massovye-izmeneniia"&gt;Массовые изменения&lt;/h2&gt;
&lt;h3 id="massovaia-vstavka"&gt;Массовая вставка&lt;/h3&gt;
&lt;p&gt;Предположим, что наше новое приложение блога заменяет старое приложение и нам нужно перенести данные в новые модели.
Мы экспортировали данные из старого приложения в огромные JSON файлы. Файл с авторами имеет следующий вид:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json
[
  {
    "username": "mackchristopher",
    "email": "dcortez@yahoo.com",
    "bio": "Vitae mollitia in modi suscipit similique. Tempore sunt aliquid porro. Molestias tempora quos corporis quam."
  }
]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Сделаем команду Django для импортирования авторов из JSON файла:&lt;/p&gt;
&lt;p&gt;```python
class Command(BaseCommand):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;help = 'Load authors from `data/old_authors.json`'

DATA_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'old_data.json')

def handle(self, *args, **kwargs):
    with open(self.DATA_FILE_PATH, 'r') as json_file:
        data = json.loads(json_file.read())
    for author in data:
        self._import_author(author)

def _import_author(self, author_data):
    author = Author(
        username=author_data['username'],
        email=author_data['email'],
        bio=author_data['bio'])
    author.save()
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Проверим сколько SQL запросов выполняется при загрузке 200 авторов. Используем &lt;code&gt;python manage.py shell&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
from django.core.management import call_command
from django.db import connection
call_command('load_data')
print(len(connection.queries))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот код выведет множество SQL запросов (т.к. у нас включено их логирование), а в последней строке будет число &lt;code&gt;200&lt;/code&gt;.
Это означает, что для каждого автора выполняется отдельный &lt;code&gt;INSERT&lt;/code&gt; SQL запрос. Если у вас большое количество данных,
то такой подход может быть очень медленным. Воспользуемся методом &lt;code&gt;bulk_create&lt;/code&gt; менеджера модели &lt;code&gt;Author&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```python
    def handle(self, &lt;em&gt;args, &lt;/em&gt;*kwargs):
        with open(self.DATA_FILE_PATH, 'r') as json_file:
            data = json.loads(json_file.read())
        author_instances = []
        for author in data:
            author_instances.append(self._import_author(author))
        Author.objects.bulk_create(author_instances)&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;def _import_author(self, author_data):
    author = Author(
        username=author_data['username'],
        email=author_data['email'],
        bio=author_data['bio'])
    return author
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Запустив команду, описанным выше способом, мы увидим, что был выполнен один огромный запрос к БД, для всех авторов.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Если вам действительно нужно вставить большой объем данных, возможно, придется разбить вставку на несколько запросов.
Для этого существует параметр &lt;code&gt;batch_size&lt;/code&gt; у метода &lt;code&gt;bulk_create&lt;/code&gt;, который задает максимальное количество объектов,
которые будут вставлены за один запрос. Т.е. если у нас 200 объектов, задав &lt;code&gt;bulk_size = 50&lt;/code&gt; мы получим 4 запроса.&lt;/p&gt;
&lt;p&gt;У метода &lt;code&gt;bulk_size&lt;/code&gt; есть ряд ограничений с которыми вы можете ознакомиться в &lt;a href="https://docs.djangoproject.com/en/1.11/ref/models/querysets/#bulk-create"&gt;документации&lt;/a&gt;.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="massovaia-vstavka-m2m"&gt;Массовая вставка M2M&lt;/h3&gt;
&lt;p&gt;Теперь нам нужно вставить статьи и теги, которые находятся в отдельном JSON файле с следующей структурой:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;json
[
  {
    "created_at": "2016-06-11",
    "author": "nichole52",
    "tags": [
      "ab",
      "iure",
      "iusto"
    ],
    "title": "...",
    "content": "..."
  }
]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Напишем для этого еще одну команду Django:&lt;/p&gt;
&lt;p&gt;```python
class Command(BaseCommand):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;help = 'Load articles from `data/old_articles.json`'

DATA_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'old_articles.json')

def handle(self, *args, **kwargs):
    with open(self.DATA_FILE_PATH, 'r') as json_file:
        data = json.loads(json_file.read())
    for article in data:
        self._import_article(article)

def _import_article(self, article_data):
    author = Author.objects.get(username=article_data['author'])
    article = Article(
        title=article_data['title'],
        content=article_data['content'],
        created_at=article_data['created_at'],
        author=author)
    article.save()
    for tag in article_data['tags']:
        tag_instance, _ = Tag.objects.get_or_create(name=tag)
        article.tags.add(tag_instance)
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Запустив ее я получил 3349 SQL запросов! Многие из которых имели следующий вид:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;SQL
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (67)); args=(2319, 67)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 67) RETURNING "blog_article_tags"."id"; args=(2319, 67)
(0.000) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" WHERE "blog_tag"."name" = 'fugiat'; args=('fugiat',)
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (68)); args=(2319, 68)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 68) RETURNING "blog_article_tags"."id"; args=(2319, 68)
(0.000) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" WHERE "blog_tag"."name" = 'repellat'; args=('repellat',)
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (58)); args=(2319, 58)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 58) RETURNING "blog_article_tags"."id"; args=(2319, 58&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Добавление каждого тега к статье выполняется отдельным запросом. Это можно улучшить передавая методу &lt;code&gt;article.tags.add&lt;/code&gt;
сразу список тегов:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
    def _import_article(self, article_data):
        # ...
        tags = []
        for tag in article_data['tags']:
            tag_instance, _ = Tag.objects.get_or_create(name=tag)
            tags.append(tag_instance)
        article.tags.add(*tags)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот вариант отправляет 1834 запроса, почти в 2 раза меньше, неплохой результат, учитывая что мы изменили всего лишь
пару строк кода.&lt;/p&gt;
&lt;h3 id="massovoe-izmenenie"&gt;Массовое изменение&lt;/h3&gt;
&lt;p&gt;После переноса данных пришла идея, что к старым статьям (раньше 2012 года) нужно запретить комментирование. Для этого
было добавлено логическое поле &lt;code&gt;comments_on&lt;/code&gt; к модели &lt;code&gt;Article&lt;/code&gt; и нам необходимо проставить его значение:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
from django.db import connection
from blog.models import Article
for article in Article.objects.filter(created_at__year__lt=2012):
    article.comments_on = False
    article.save()
print(len(connection.queries))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Запустив этот код я получил 179 запросов следующего вида:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.000) UPDATE "blog_article" SET "title" = 'Saepe eius facere magni et eligendi minima sint.', "content" = '...', "created_at" = '1992-03-01'::date, "author_id" = 730, "comments_on" = false WHERE "blog_article"."id" = 3507; args=('Saepe eius facere magni et eligendi minima sint.', '...', datetime.date(1992, 3, 1), 730, False, 3507)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Кроме того, что для каждой статьи подходящей по условию происходит отдельный SQL запрос, еще и все поля этих статей
перезаписываются. А это может привести к перезаписи изменений сделанных в промежутке между &lt;code&gt;SELECT&lt;/code&gt; и &lt;code&gt;UPDATE&lt;/code&gt; запросами.
Т.е. кроме проблем с производительностью мы также получаем race condition.&lt;/p&gt;
&lt;p&gt;Вместо этого мы можем использовать метод &lt;code&gt;update&lt;/code&gt; доступный у объектов &lt;code&gt;QuerySet&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
Article.objects.filter(created_at__year__lt=2012).update(comments_on=False)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот код генерирует всего один SQL запрос:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.004) UPDATE "blog_article" SET "comments_on" = false WHERE "blog_article"."created_at" &amp;lt; '2012-01-01'::date; args=(False, datetime.date(2012, 1, 1))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Если для изменения полей нужна сложная логика, которую нельзя реализовать полностью в update операторе, можете вычислить
значение поля в Python коде и затем использовать один из следующих вариантов:&lt;/p&gt;
&lt;p&gt;```python
Model.object.filter(id=instance.id).update(field=computed_value)&lt;/p&gt;
&lt;h1 id="or_2"&gt;or&lt;/h1&gt;
&lt;p&gt;instance.field = computed_value
instance.save(update_fields=('fields',))
```&lt;/p&gt;
&lt;p&gt;Но оба эти варианта также страдают от race condition, хоть и в меньшей степени.&lt;/p&gt;
&lt;h3 id="massovoe-udalenie-obektov"&gt;Массовое удаление объектов&lt;/h3&gt;
&lt;p&gt;Сейчас нам потребовалось удалить все статьи отмеченные тегом &lt;code&gt;minus&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
from django.db import connection
from blog.models import Article
for article in Article.objects.filter(tags__name='minus'):
    article.delete()
print(len(connection.queries))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Код сгенерировал 93 запроса следующего вида:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.000) DELETE FROM "blog_article_tags" WHERE "blog_article_tags"."article_id" IN (3510); args=(3510,)
(0.000) DELETE FROM "blog_article" WHERE "blog_article"."id" IN (3510); args=(3510,)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Сначала удаляется связь статьи с тегом в промежуточной таблице, а затем и сама статья. Мы можем сделать это за
меньшее количество запросов, используя метод &lt;code&gt;delete&lt;/code&gt; класса &lt;code&gt;QuerySet&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
from django.db import connection
from blog.models import Article
Article.objects.filter(tags__name='minus').delete()
print(len(connection.queries))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот код выполняет то же самое всего за 3 запроса к БД:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.004) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" INNER JOIN "blog_article_tags" ON ("blog_article"."id" = "blog_article_tags"."article_id") INNER JOIN "blog_tag" ON ("blog_article_tags"."tag_id" = "blog_tag"."id") WHERE "blog_tag"."name" = 'minus'; args=('minus',)
(0.002) DELETE FROM "blog_article_tags" WHERE "blog_article_tags"."article_id" IN (3713, 3717, 3722, ...); args=(3713, 3717, 3722, ...)
(0.001) DELETE FROM "blog_article" WHERE "blog_article"."id" IN (3713, 3717, ...); args=(3713, 3717, 3722, ...)``sql&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Сначала одним запросом получается список идентификаторов всех статей, отмеченных тегом &lt;code&gt;minus&lt;/code&gt;, затем второй запрос
удаляет связи сразу всех этих статей с тегами, и последний запрос удаляет статьи.&lt;/p&gt;
&lt;h2 id="iterator_1"&gt;Iterator&lt;/h2&gt;
&lt;p&gt;Предположим, нам нужно добавить возможность экспорта статей в CSV формат. Сделаем для этого простую команду Django:&lt;/p&gt;
&lt;p&gt;```python
class Command(BaseCommand):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;help = 'Export articles to csv'

EXPORT_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'articles_export.csv')
COLUMNS = ['title', 'content', 'created_at', 'author', 'comments_on']

def handle(self, *args, **kwargs):
    with open(self.EXPORT_FILE_PATH, 'w') as export_file:
        articles_writer = csv.writer(export_file, delimiter=';')
        articles_writer.writerow(self.COLUMNS)
        for article in Article.objects.select_related('author').all():
            articles_writer.writerow([getattr(article, column) for column in self.COLUMNS])
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Для тестирования этой команды я сгенерировал около 100Мb статей и загрузил их в БД. Далее я запустил команду через профайлер
памяти &lt;a href="https://pypi.python.org/pypi/memory_profiler"&gt;memory_profiler&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mprof run python manage.py export_articles
mprof plot&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;В результате я получил следующий график по использованию памяти:&lt;/p&gt;
&lt;p&gt;&lt;img alt="export articles profiling" src="/media/2017/6/export_articles_without_iterator.png"/&gt;&lt;/p&gt;
&lt;p&gt;Команда использует около 250Mb памяти, потому что при выполнении запроса &lt;code&gt;QuerySet&lt;/code&gt; получает из БД сразу все статьи и
кэширует их в памяти, чтобы при последующем обращении к этому &lt;code&gt;QuerySet&lt;/code&gt; дополнительные запросы не выполнялись.
Мы можем уменьшить объем используемой памяти, используя метод &lt;code&gt;iterator&lt;/code&gt; класса &lt;code&gt;QuerySet&lt;/code&gt;, который позволяет получать
результаты по одному, используя &lt;a href="http://initd.org/psycopg/docs/cursor.html"&gt;server-side cursor&lt;/a&gt;, и при этом он отключает
кэширование результатов в &lt;code&gt;QuerySet&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```python&lt;/p&gt;
&lt;h1 id="_2"&gt;...&lt;/h1&gt;
&lt;p&gt;for article in Article.objects.select_related('author').iterator():&lt;/p&gt;
&lt;h1 id="_3"&gt;...&lt;/h1&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Запустив обновленный пример в профайлере я получил следующий результат:&lt;/p&gt;
&lt;p&gt;&lt;img alt="export articles profiling" src="/media/2017/6/export_articles_with_iterator.png"/&gt;&lt;/p&gt;
&lt;p&gt;Теперь команда использует всего 50Mb. Также приятным побочным эффектом является то, что при любом размере данных,
при использовании &lt;code&gt;iterator&lt;/code&gt;, команда использует постоянный объем памяти. Вот графики для ~200Mb статей
(без &lt;code&gt;iterator&lt;/code&gt; и с ним соответственно):&lt;/p&gt;
&lt;p&gt;&lt;img alt="huge export articles profiling" src="/media/2017/6/export_articles_huge_before_and_after.png"/&gt;&lt;/p&gt;
&lt;h2 id="ispolzovanie-vneshnikh-kliuchei"&gt;Использование внешних ключей&lt;/h2&gt;
&lt;p&gt;Теперь нам потребовалось добавить действие в админку статей для создания копии статьи:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def clone_article(modeladmin, request, queryset):
    if queryset.count() != 1:
        modeladmin.message_user(request, "You could clone only one article at a time.", level=messages.ERROR)
        return
    origin_article = queryset.first()
    cloned_article = Article(
        title="{} (COPY)".format(origin_article.title),
        content=origin_article.content,
        created_at=origin_article.created_at,
        author=origin_article.author,
        comments_on=origin_article.comments_on)
    cloned_article.save()
    cloned_article.tags = origin_article.tags.all()
    modeladmin.message_user(request, "Article successfully cloned", level=messages.SUCCESS)
clone_article.short_description = 'Clone article'&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;В логах можно увидеть следующие запросы к БД:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.001) SELECT COUNT(*) AS "__count" FROM "blog_article" WHERE "blog_article"."id" IN (31582); args=(31582,)
(0.001) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" WHERE "blog_article"."id" IN (31582) ORDER BY "blog_article"."created_at" DESC, "blog_article"."id" DESC LIMIT 1; args=(31582,)
(0.000) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2156; args=(2156,)
(0.001) INSERT INTO "blog_article" ("title", "content", "created_at", "author_id", "comments_on") VALUES ('Explicabo maiores nobis cum vel fugit. (COPY)', ...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;У нас почему-то запрашивается автор, хотя нам не нужны какие-либо данные об авторе, кроме его ID. Чтобы исправить это,
нужно обращаться к внешнему ключу напрямую, для получения id автора нужно использовать &lt;code&gt;origin_article.author_id&lt;/code&gt;.
Теперь код клонирования статьи будет выглядеть следующим образом:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
cloned_article = Article(
    title="{} (COPY)".format(origin_article.title),
    content=origin_article.content,
    created_at=origin_article.created_at,
    author_id=origin_article.author_id,
    comments_on=origin_article.comments_on)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;И в логах больше нет запросов на получение информации об авторе.&lt;/p&gt;
&lt;h2 id="poluchenie-sviazannykh-obektov"&gt;Получение связанных объектов&lt;/h2&gt;
&lt;p&gt;Наконец-то пришло время сделать наши статьи публично доступными, и начнем мы со страницы со списком статей. Реализуем
view, используя &lt;code&gt;ListView&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;```python
class ArticlesListView(ListView):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;template_name = 'blog/articles_list.html'
model = Article
context_object_name = 'articles'
paginate_by = 20
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;В шаблоне мы выводим информацию о статье, авторе и тегах:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;django
&amp;lt;article&amp;gt;
    &amp;lt;h2&amp;gt;{{ article.title }}&amp;lt;/h2&amp;gt;
    &amp;lt;time&amp;gt;{{ article.created_at }}&amp;lt;/time&amp;gt;
    &amp;lt;p&amp;gt;Author: {{ article.author.username }}&amp;lt;/p&amp;gt;
    &amp;lt;p&amp;gt;Tags:
    {% for tag in article.tags.all %}
        {{ tag }}{% if not forloop.last %}, {% endif %}
    {% endfor %}
&amp;lt;/article&amp;gt;&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;DDT показывает при открытии списка статей 45 SQL запросов следующего вида:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.002) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" LIMIT 20; args=()
(0.001) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2043; args=(2043,)
(0.001) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" = 20425; args=(20425,)
(0.000) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2043; args=(2043,)
(0.001) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" = 20426; args=(20426,)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Т.е. мы сначала получаем все статьи одним SQL запросом (с учетом пагинации) и затем для каждой из этих статей отдельно
запрашиваются автор и теги. Нам нужно заставить Django запросить все эти данные меньшим количеством запросов.&lt;/p&gt;
&lt;p&gt;Начнем с получения авторов, для того, чтобы &lt;code&gt;QuerySet&lt;/code&gt; получил заранее данные по определенным внешним ключам есть метод &lt;code&gt;select_related&lt;/code&gt;. Обновим &lt;code&gt;queryset&lt;/code&gt; в нашем view для использования этого метода:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
queryset = Article.objects.select_related('author')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;После этого DDT показывает уже 25 SQL запросов, т.к. получение информации об авторах и статьях теперь выполняется одним
SQL запросом с &lt;code&gt;JOIN&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.004) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on", "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_article" INNER JOIN "blog_author" ON ("blog_article"."author_id" = "blog_author"."id") LIMIT 21; args=()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Метод &lt;code&gt;select_related&lt;/code&gt; работает только с внешними ключами в текущей модели, для того, чтобы уменьшить количество запросов
при получении множества связанных объектов (таких как теги в нашем примере), нужно использовать метод &lt;code&gt;prefetch_related&lt;/code&gt;.
Опять обновим атрибут &lt;code&gt;queryset&lt;/code&gt; у класса &lt;code&gt;AticlsListView&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
queryset = Article.objects.select_related('author').prefetch_related('tags')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;И теперь DDT показывает всего 7 запросов. Если проигнорировать запросы, которые выполняет пагинатор и запросы, связанные
с сессией получаем всего 2 запроса для отображения списка статей:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sql
(0.002) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on", "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_article" INNER JOIN "blog_author" ON ("blog_article"."author_id" = "blog_author"."id") LIMIT 20; args=()
(0.001) SELECT ("blog_article_tags"."article_id") AS "_prefetch_related_val_article_id", "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" IN (16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351); args=(16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351)&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Используйте &lt;code&gt;select_related&lt;/code&gt; для внешних ключей в текущей модели. Для получения M2M объектов и объектов из моделей
ссылающихся на текущую, используйте &lt;code&gt;prefetch_related&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Также &lt;code&gt;prefetch_related&lt;/code&gt; можно использовать для получения связанных объектов большей вложенности: &lt;/p&gt;
&lt;p&gt;&lt;code&gt;Tag.objects.all().prefetch_related('article_set__author')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот код запросит вместе с тегом также все статьи отмеченные тегом и всех авторов этих статей.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="ogranichenie-polei-v-vyborkakh"&gt;Ограничение полей в выборках&lt;/h2&gt;
&lt;p&gt;Если мы присмотримся получше к SQL запросам в предыдущем примере, мы увидим, что мы получаем больше полей, чем нам нужно.
В DDT можно посмотреть результаты запроса и убедиться в этом:&lt;/p&gt;
&lt;p&gt;&lt;img alt="SQL query result for articles list" src="/media/2017/6/sql-queries-results.png"/&gt;&lt;/p&gt;
&lt;p&gt;Мы получаем все поля автора и статьи, включая текст статьи огромного размера. Можно значительно
уменьшить объем передаваемых данных, используя метод defer, который позволяет отложить получение определенных полей.
В случае, если в коде все же произойдет обращение к такому полю, то Django сделает дополнительный запрос для его получения.
Добавим вызов метода &lt;code&gt;defer&lt;/code&gt; в &lt;code&gt;queryset&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
queryset = Article.objects.select_related('author').prefetch_related('tags').defer('content', 'comments_on')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Теперь некоторые ненужные поля не запрашиваются и это уменьшило время обработки запроса, как нам показывает DDT
(до и после &lt;code&gt;defer&lt;/code&gt; соответственно):&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - SQL speedup after defer" src="/media/2017/6/sql-speedup-defer.png"/&gt;&lt;/p&gt;
&lt;p&gt;Мы все еще получаем множество полей автора, которые мы не используем. Проще было бы указать только те поля,
которые нам действительно нужны. Для этого есть метод &lt;code&gt;only&lt;/code&gt;, передав которому названия полей, остальные поля будут отложены:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
queryset = Article.objects.select_related('author').prefetch_related('tags').only(
    'title', 'created_at', 'author__username', 'tags__name')&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;В результате мы получаем только нужные данные, что можно посмотреть в DDT:&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - SQL after only" src="/media/2017/6/sql-after-only.png"/&gt;&lt;/p&gt;
&lt;p&gt;Т.е. &lt;code&gt;defer&lt;/code&gt; и &lt;code&gt;only&lt;/code&gt; выполняют одну и ту же задачу, ограничения полей в выборках, различие только в то что:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;defer&lt;/code&gt; откладывает получение полей переданных в качестве аргументов,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;only&lt;/code&gt; откладывает получение всех полей, кроме переданных.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="indeksy-bd"&gt;Индексы БД&lt;/h2&gt;
&lt;p&gt;Нам нужно сделать страницу автора, которая будет доступна по такому URL: &lt;code&gt;/authors/&amp;lt;username&amp;gt;&lt;/code&gt;. Сделаем view
для этого:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def author_page_view(request, username):
    author = get_object_or_404(Author, username=username)
    return render(request, 'blog/author.html', context=dict(author=author))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Этот код работает достаточно быстро при небольшом объеме данных, но если объем значительный и продолжает расти, то
производительность будет только падать. Все дело в том, что для поиска по полю &lt;code&gt;username&lt;/code&gt; СУБД приходится сканировать
всю таблицу до тех пор пока не найдет нужное значение. Есть вариант лучше - добавить на данное поле индекс, что позволит
СУБД искать гораздо эффективнее. Для добавления индекса нужно добавить аргумент &lt;code&gt;db_index=True&lt;/code&gt; в объявление
поля &lt;code&gt;username&lt;/code&gt;, а затем создать и применить миграции:&lt;/p&gt;
&lt;p&gt;```python
class Author(models.Model):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;username = models.CharField(max_length=64, db_index=True)
# ...
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Сравним производительность до и после добавления индекса на БД авторов размером в 100К.&lt;/p&gt;
&lt;p&gt;Без индекса:&lt;/p&gt;
&lt;p&gt;&lt;img alt="select by username without index" src="/media/2017/6/ddt-select-by-username-without-index.png"/&gt;&lt;/p&gt;
&lt;p&gt;С индексом:&lt;/p&gt;
&lt;p&gt;&lt;img alt="select by username with index" src="/media/2017/6/ddt-select-by-username-with-index.png"/&gt;&lt;/p&gt;
&lt;p&gt;Запрос выполнился быстрее в 16 раз!&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Индексы полезны не только при фильтрации данных, но и при сортировке. Также многие СУБД позволяют делать индексы по
нескольким полям, что полезно, если вы фильтруете данные по набору полей. Советую изучить документацию к вашей СУБД,
чтобы узнать подробности.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="lenqs-vs-qscount"&gt;len(qs) vs qs.count&lt;/h2&gt;
&lt;p&gt;По какой-то причине, нам потребовалось вывести на странице со списком статей счетчик с количеством авторов. Обновим view:&lt;/p&gt;
&lt;p&gt;```python
class ArticlesListView(ListView):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# ...

def get_context_data(self, **kwargs):
    context = super().get_context_data(**kwargs)
    context['authors_count'] = len(Author.objects.all())
    return context
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;```&lt;/p&gt;
&lt;p&gt;Посмотрим какие SQL запросы генерирует этот код:&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - len(qs)" src="/media/2017/6/ddt-authors-len-queryset.png"/&gt;&lt;/p&gt;
&lt;p&gt;На скриншоте мы видим, что запрашиваются все значения из таблицы авторов, соответственно подсчет количества происходит
уже в самом view. Конечно это не самый оптимальный вариант и нам было бы достаточно получить из БД одно число -
количество авторов. Для этого можно использовать метод &lt;code&gt;count&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
        context['authors_count'] = Author.objects.count()&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Посмотрим результат в DDT:&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - len(qs)" src="/media/2017/6/ddt-authors-count.png"/&gt;&lt;/p&gt;
&lt;p&gt;Теперь Django сгенерировал намного более оптимальный запрос для нашей задачи.&lt;/p&gt;
&lt;h2 id="count-vs-exists"&gt;count vs exists&lt;/h2&gt;
&lt;p&gt;На странице автора нужно вывести ссылку на каталог статей этого автора, если у него есть статьи. Одним из решений будет
получить количество статей и сравнить равно ли количество 0, например так:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
def author_page_view(request, username):
    author = get_object_or_404(Author, username=username)
    show_articles_link = (author.articles.count() &amp;gt; 0)
    return render(
        request, 'blog/author.html',
        context=dict(author=author, show_articles_link=show_articles_link))&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Но при большом количестве статей этот код будет работать медленно. Т.к. нам не нужно знать точное количество статей
у пользователя, то мы можем использовать метод &lt;code&gt;exists&lt;/code&gt;, который проверяет, что в &lt;code&gt;QuertSet&lt;/code&gt; есть хотя бы один результат:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
    # ...
    show_articles_link = author.articles.exists()
    # ...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Сравниваем производительность при большом количестве статей (~10K):&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - exists vs count" src="/media/2017/6/ddt-exists-vs-count.png"/&gt;&lt;/p&gt;
&lt;p&gt;Мы достигли цели запросом, который выполняется в 10 раз быстрее.&lt;/p&gt;
&lt;h2 id="lenivyi-queryset"&gt;Ленивый QuerySet&lt;/h2&gt;
&lt;p&gt;Теперь нам захотелось, чтобы авторы конкурировали между собой, для этого мы добавим рейтинг топ-20 авторов по количеству
статей.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
class ArticlesListView(ListView):
    # ...
    def get_context_data(self, **kwargs):
        # ...
        context['top_authors'] = list(
            Author.objects.order_by('-articles_count'))[:20]
        # ...&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Здесь мы получаем список всех авторов, отсортированный по количеству статей, и берем первые 20 элементов этого списка.
&lt;code&gt;articles_count&lt;/code&gt;, в нашем примере, это денормализованное поле, которое содержит количество статей у данного автора.
На реальном проекте, возможно вы захотели бы настроить сигналы, для актуализации этого поля.&lt;/p&gt;
&lt;p&gt;Думаю уже сейчас понятно, что это не самый оптимальный вариант, это подтверждает и DDT:&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - get top authors slice" src="/media/2017/6/ddt-top-authors-list.png"/&gt;&lt;/p&gt;
&lt;p&gt;Конечно нам нужно, чтобы ограничение выборки первыми 20-ю авторами происходило на стороне БД. Для этого нужно понять,
что &lt;code&gt;QuerySet&lt;/code&gt; старается максимально отсрочить выполнение запроса к БД. Непосредственно запрос к БД осуществляется в
следующих случаях:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;итерация по QuerySet (например, &lt;code&gt;for obj in Model.objects.all():&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;slicing, если вы используете "нарезку" с определенным шагом (например, &lt;code&gt;Model.objects.all()[::2]&lt;/code&gt;),&lt;/li&gt;
&lt;li&gt;применение метода &lt;code&gt;len&lt;/code&gt; (например, &lt;code&gt;len(Model.objects.all())&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;применение метода &lt;code&gt;list&lt;/code&gt; (например, &lt;code&gt;list(Model.objects.all())&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;применение метода &lt;code&gt;bool&lt;/code&gt; (например, &lt;code&gt;bool(Model.objects.all())&lt;/code&gt;,&lt;/li&gt;
&lt;li&gt;сериализация при помощи &lt;a href="https://docs.python.org/3/library/pickle.html"&gt;pickle&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Т.е. вызвав &lt;code&gt;list&lt;/code&gt; мы заставили &lt;code&gt;QuerySet&lt;/code&gt; выполнить запрос к БД и вернуть нам список объектов, после чего уже к нему была
применена операция обрезки. Для того, чтобы ограничение выборки происходило в SQL запросе, нужно применить slicing
к самому &lt;code&gt;QuerySet&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;python
context['top_authors'] =\
    Author.objects.order_by('-articles_count')[:20]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="DDT - get top authors slice on queryset" src="/media/2017/6/ddt-top-authors-qs-slice.png"/&gt;&lt;/p&gt;
&lt;p&gt;Теперь размер выборки ограничивается в запросе: &lt;code&gt;...LIMIT 20&lt;/code&gt;. Также видно, что отправка запроса
к БД была отложена до итерации по циклу в шаблоне.&lt;/p&gt;</content><category term="python"></category><category term="django"></category></entry></feed>