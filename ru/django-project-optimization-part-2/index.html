<!DOCTYPE html>
<html lang="ru">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
    <meta name="HandheldFriendly" content="true">
    <meta http-equiv="x-ua-compatible" content="ie=edge">
    <title>Оптимизация производительности Django проектов (часть 2)</title>
    <link rel="stylesheet" href="/theme/css/native.css" />
    <link rel="stylesheet" type="text/css" href="/theme/css/main.css" />
    <link href="https://fonts.googleapis.com/css?family=PT+Serif&amp;subset=cyrillic" rel="stylesheet">
    <link href="https://fonts.googleapis.com/css?family=PT+Mono&amp;subset=cyrillic" rel="stylesheet">
    <!--[if IE]><script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
      ga('create', 'UA-20497524-1', 'auto');
      ga('send', 'pageview');
    </script>
	
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
  "HTML-CSS": {
  styles: {
  ".MathJax .mo, .MathJax .mi": {color: "black ! important"}}
  },
  tex2jax: {inlineMath: [['$','$'], ['\\\\(','\\\\)']],processEscapes: true}
  });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body id="index" class="home">
        <header id="banner" class="body">
            <h1><a href="/ru/">Tech blog by @dizballanze <strong></strong></a></h1>
            <div id="langs">
                <a href="/">En</a>
                <a href="/ru/">Ru</a>
            </div>
        </header><!-- /#banner -->
        <nav id="menu"><ul>
            <li><a href="/ru/about-me/">Автор</a></li>
            <li><a href="https://wbtech.pro/">WB–Tech</a></li>
            <li><a href="https://debugmail.io/">DebugMail</a></li>
        </ul>
        </nav><!-- /#menu -->
<section id="content" class="body">
  <header>
    <h2 class="entry-title">
      <a href="/ru/django-project-optimization-part-2/" rel="bookmark"
         title="Permalink to Оптимизация производительности Django проектов (часть 2)">Оптимизация производительности Django проектов (часть 2)</a></h2>
    <time class="published" datetime="2017-06-27T16:00:00+03:00"><nobr>27 июн 2017</nobr></time>
  </header>
  <div class="entry-content">
    <p>Содержание:</p>
<ul>
<li><a href="#massovye-izmeneniia">Массовые изменения</a><ul>
<li><a href="#massovaia-vstavka">Массовая вставка</a></li>
<li><a href="#massovaia-vstavka-m2m">Массовая вставка M2M</a></li>
<li><a href="#massovoe-izmenenie">Массовое изменение</a></li>
<li><a href="#massovoe-udalenie-obektov">Массовое удаление объектов</a></li>
</ul>
</li>
<li><a href="#iterator_1">Iterator</a></li>
<li><a href="#ispolzovanie-vneshnikh-kliuchei">Использование внешних ключей</a></li>
<li><a href="#poluchenie-sviazannykh-obektov">Получение связанных объектов</a></li>
<li><a href="#ogranichenie-polei-v-vyborkakh">Ограничение полей в выборках</a></li>
<li><a href="#indeksy-bd">Индексы БД</a></li>
<li><a href="#lenqs-vs-qscount">len(qs) vs qs.count</a></li>
<li><a href="#count-vs-exists">count vs exists</a></li>
<li><a href="#lenivyi-queryset">Ленивый QuerySet</a></li>
</ul>
<p>Это продолжение серии статей про оптимизацию Django приложений. Первая часть доступна
<a href="/ru/django-project-optimization-part-1/">здесь</a> и рассказывает о профилировании и настройках Django. В этой части
мы рассмотрим оптимизацию работы с БД (модели Django).</p>
<p>В этой части часто будет использоваться логирование SQL запросов и DDT, про которые написано в первом посте.
В качестве БД во всех примерах будет использоваться PostgreSQL, но для пользователей других СУБД большая часть статьи
также будет актуальна.</p>
<p>Примеры в этой части будут основаны на простом приложении блога, которое мы будем разрабатывать и оптимизировать по
ходу статьи. Начнем с следующих моделей:</p>
<p>```python
from django.db import models</p>
<p>class Tag(models.Model):</p>
<pre><code>name = models.CharField(max_length=64)

def __str__(self):
    return self.name
</code></pre>
<p>class Author(models.Model):</p>
<pre><code>username = models.CharField(max_length=64)
email = models.EmailField()
bio = models.TextField()

def __str__(self):
    return self.username
</code></pre>
<p>class Article(models.Model):</p>
<pre><code>title = models.CharField(max_length=64)
content = models.TextField()
created_at = models.DateField()
author = models.ForeignKey(Author)
tags = models.ManyToManyField(Tag)

def __str__(self):
    return self.title
</code></pre>
<p>```</p>
<p>Весь код доступен на <a href="https://github.com/dizballanze/django-optimization-guide-2-sample/tree/initial">GitHub</a>
с разбивкой по <a href="https://github.com/dizballanze/django-optimization-guide-2-sample/tags">тегам</a>.</p>
<h2 id="massovye-izmeneniia">Массовые изменения</h2>
<h3 id="massovaia-vstavka">Массовая вставка</h3>
<p>Предположим, что наше новое приложение блога заменяет старое приложение и нам нужно перенести данные в новые модели.
Мы экспортировали данные из старого приложения в огромные JSON файлы. Файл с авторами имеет следующий вид:</p>
<p><code>json
[
  {
    "username": "mackchristopher",
    "email": "dcortez@yahoo.com",
    "bio": "Vitae mollitia in modi suscipit similique. Tempore sunt aliquid porro. Molestias tempora quos corporis quam."
  }
]</code></p>
<p>Сделаем команду Django для импортирования авторов из JSON файла:</p>
<p>```python
class Command(BaseCommand):</p>
<pre><code>help = 'Load authors from `data/old_authors.json`'

DATA_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'old_data.json')

def handle(self, *args, **kwargs):
    with open(self.DATA_FILE_PATH, 'r') as json_file:
        data = json.loads(json_file.read())
    for author in data:
        self._import_author(author)

def _import_author(self, author_data):
    author = Author(
        username=author_data['username'],
        email=author_data['email'],
        bio=author_data['bio'])
    author.save()
</code></pre>
<p>```</p>
<p>Проверим сколько SQL запросов выполняется при загрузке 200 авторов. Используем <code>python manage.py shell</code>:</p>
<p><code>python
from django.core.management import call_command
from django.db import connection
call_command('load_data')
print(len(connection.queries))</code></p>
<p>Этот код выведет множество SQL запросов (т.к. у нас включено их логирование), а в последней строке будет число <code>200</code>.
Это означает, что для каждого автора выполняется отдельный <code>INSERT</code> SQL запрос. Если у вас большое количество данных,
то такой подход может быть очень медленным. Воспользуемся методом <code>bulk_create</code> менеджера модели <code>Author</code>:</p>
<p>```python
    def handle(self, <em>args, </em>*kwargs):
        with open(self.DATA_FILE_PATH, 'r') as json_file:
            data = json.loads(json_file.read())
        author_instances = []
        for author in data:
            author_instances.append(self._import_author(author))
        Author.objects.bulk_create(author_instances)</p>
<pre><code>def _import_author(self, author_data):
    author = Author(
        username=author_data['username'],
        email=author_data['email'],
        bio=author_data['bio'])
    return author
</code></pre>
<p>```</p>
<p>Запустив команду, описанным выше способом, мы увидим, что был выполнен один огромный запрос к БД, для всех авторов.</p>
<blockquote>
<p>Если вам действительно нужно вставить большой объем данных, возможно, придется разбить вставку на несколько запросов.
Для этого существует параметр <code>batch_size</code> у метода <code>bulk_create</code>, который задает максимальное количество объектов,
которые будут вставлены за один запрос. Т.е. если у нас 200 объектов, задав <code>bulk_size = 50</code> мы получим 4 запроса.</p>
<p>У метода <code>bulk_size</code> есть ряд ограничений с которыми вы можете ознакомиться в <a href="https://docs.djangoproject.com/en/1.11/ref/models/querysets/#bulk-create">документации</a>.</p>
</blockquote>
<h3 id="massovaia-vstavka-m2m">Массовая вставка M2M</h3>
<p>Теперь нам нужно вставить статьи и теги, которые находятся в отдельном JSON файле с следующей структурой:</p>
<p><code>json
[
  {
    "created_at": "2016-06-11",
    "author": "nichole52",
    "tags": [
      "ab",
      "iure",
      "iusto"
    ],
    "title": "...",
    "content": "..."
  }
]</code></p>
<p>Напишем для этого еще одну команду Django:</p>
<p>```python
class Command(BaseCommand):</p>
<pre><code>help = 'Load articles from `data/old_articles.json`'

DATA_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'old_articles.json')

def handle(self, *args, **kwargs):
    with open(self.DATA_FILE_PATH, 'r') as json_file:
        data = json.loads(json_file.read())
    for article in data:
        self._import_article(article)

def _import_article(self, article_data):
    author = Author.objects.get(username=article_data['author'])
    article = Article(
        title=article_data['title'],
        content=article_data['content'],
        created_at=article_data['created_at'],
        author=author)
    article.save()
    for tag in article_data['tags']:
        tag_instance, _ = Tag.objects.get_or_create(name=tag)
        article.tags.add(tag_instance)
</code></pre>
<p>```</p>
<p>Запустив ее я получил 3349 SQL запросов! Многие из которых имели следующий вид:</p>
<p><code>SQL
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (67)); args=(2319, 67)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 67) RETURNING "blog_article_tags"."id"; args=(2319, 67)
(0.000) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" WHERE "blog_tag"."name" = 'fugiat'; args=('fugiat',)
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (68)); args=(2319, 68)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 68) RETURNING "blog_article_tags"."id"; args=(2319, 68)
(0.000) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" WHERE "blog_tag"."name" = 'repellat'; args=('repellat',)
(0.001) SELECT "blog_article_tags"."tag_id" FROM "blog_article_tags" WHERE ("blog_article_tags"."article_id" = 2319 AND "blog_article_tags"."tag_id" IN (58)); args=(2319, 58)
(0.000) INSERT INTO "blog_article_tags" ("article_id", "tag_id") VALUES (2319, 58) RETURNING "blog_article_tags"."id"; args=(2319, 58</code></p>
<p>Добавление каждого тега к статье выполняется отдельным запросом. Это можно улучшить передавая методу <code>article.tags.add</code>
сразу список тегов:</p>
<p><code>python
    def _import_article(self, article_data):
        # ...
        tags = []
        for tag in article_data['tags']:
            tag_instance, _ = Tag.objects.get_or_create(name=tag)
            tags.append(tag_instance)
        article.tags.add(*tags)</code></p>
<p>Этот вариант отправляет 1834 запроса, почти в 2 раза меньше, неплохой результат, учитывая что мы изменили всего лишь
пару строк кода.</p>
<h3 id="massovoe-izmenenie">Массовое изменение</h3>
<p>После переноса данных пришла идея, что к старым статьям (раньше 2012 года) нужно запретить комментирование. Для этого
было добавлено логическое поле <code>comments_on</code> к модели <code>Article</code> и нам необходимо проставить его значение:</p>
<p><code>python
from django.db import connection
from blog.models import Article
for article in Article.objects.filter(created_at__year__lt=2012):
    article.comments_on = False
    article.save()
print(len(connection.queries))</code></p>
<p>Запустив этот код я получил 179 запросов следующего вида:</p>
<p><code>sql
(0.000) UPDATE "blog_article" SET "title" = 'Saepe eius facere magni et eligendi minima sint.', "content" = '...', "created_at" = '1992-03-01'::date, "author_id" = 730, "comments_on" = false WHERE "blog_article"."id" = 3507; args=('Saepe eius facere magni et eligendi minima sint.', '...', datetime.date(1992, 3, 1), 730, False, 3507)</code></p>
<p>Кроме того, что для каждой статьи подходящей по условию происходит отдельный SQL запрос, еще и все поля этих статей
перезаписываются. А это может привести к перезаписи изменений сделанных в промежутке между <code>SELECT</code> и <code>UPDATE</code> запросами.
Т.е. кроме проблем с производительностью мы также получаем race condition.</p>
<p>Вместо этого мы можем использовать метод <code>update</code> доступный у объектов <code>QuerySet</code>:</p>
<p><code>python
Article.objects.filter(created_at__year__lt=2012).update(comments_on=False)</code></p>
<p>Этот код генерирует всего один SQL запрос:</p>
<p><code>sql
(0.004) UPDATE "blog_article" SET "comments_on" = false WHERE "blog_article"."created_at" &lt; '2012-01-01'::date; args=(False, datetime.date(2012, 1, 1))</code></p>
<p>Если для изменения полей нужна сложная логика, которую нельзя реализовать полностью в update операторе, можете вычислить
значение поля в Python коде и затем использовать один из следующих вариантов:</p>
<p>```python
Model.object.filter(id=instance.id).update(field=computed_value)</p>
<h1 id="or_2">or</h1>
<p>instance.field = computed_value
instance.save(update_fields=('fields',))
```</p>
<p>Но оба эти варианта также страдают от race condition, хоть и в меньшей степени.</p>
<h3 id="massovoe-udalenie-obektov">Массовое удаление объектов</h3>
<p>Сейчас нам потребовалось удалить все статьи отмеченные тегом <code>minus</code>:</p>
<p><code>python
from django.db import connection
from blog.models import Article
for article in Article.objects.filter(tags__name='minus'):
    article.delete()
print(len(connection.queries))</code></p>
<p>Код сгенерировал 93 запроса следующего вида:</p>
<p><code>sql
(0.000) DELETE FROM "blog_article_tags" WHERE "blog_article_tags"."article_id" IN (3510); args=(3510,)
(0.000) DELETE FROM "blog_article" WHERE "blog_article"."id" IN (3510); args=(3510,)</code></p>
<p>Сначала удаляется связь статьи с тегом в промежуточной таблице, а затем и сама статья. Мы можем сделать это за
меньшее количество запросов, используя метод <code>delete</code> класса <code>QuerySet</code>:</p>
<p><code>python
from django.db import connection
from blog.models import Article
Article.objects.filter(tags__name='minus').delete()
print(len(connection.queries))</code></p>
<p>Этот код выполняет то же самое всего за 3 запроса к БД:</p>
<p><code>sql
(0.004) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" INNER JOIN "blog_article_tags" ON ("blog_article"."id" = "blog_article_tags"."article_id") INNER JOIN "blog_tag" ON ("blog_article_tags"."tag_id" = "blog_tag"."id") WHERE "blog_tag"."name" = 'minus'; args=('minus',)
(0.002) DELETE FROM "blog_article_tags" WHERE "blog_article_tags"."article_id" IN (3713, 3717, 3722, ...); args=(3713, 3717, 3722, ...)
(0.001) DELETE FROM "blog_article" WHERE "blog_article"."id" IN (3713, 3717, ...); args=(3713, 3717, 3722, ...)``sql</code></p>
<p>Сначала одним запросом получается список идентификаторов всех статей, отмеченных тегом <code>minus</code>, затем второй запрос
удаляет связи сразу всех этих статей с тегами, и последний запрос удаляет статьи.</p>
<h2 id="iterator_1">Iterator</h2>
<p>Предположим, нам нужно добавить возможность экспорта статей в CSV формат. Сделаем для этого простую команду Django:</p>
<p>```python
class Command(BaseCommand):</p>
<pre><code>help = 'Export articles to csv'

EXPORT_FILE_PATH = os.path.join(settings.BASE_DIR, '..', 'data', 'articles_export.csv')
COLUMNS = ['title', 'content', 'created_at', 'author', 'comments_on']

def handle(self, *args, **kwargs):
    with open(self.EXPORT_FILE_PATH, 'w') as export_file:
        articles_writer = csv.writer(export_file, delimiter=';')
        articles_writer.writerow(self.COLUMNS)
        for article in Article.objects.select_related('author').all():
            articles_writer.writerow([getattr(article, column) for column in self.COLUMNS])
</code></pre>
<p>```</p>
<p>Для тестирования этой команды я сгенерировал около 100Мb статей и загрузил их в БД. Далее я запустил команду через профайлер
памяти <a href="https://pypi.python.org/pypi/memory_profiler">memory_profiler</a>.</p>
<p><code>mprof run python manage.py export_articles
mprof plot</code></p>
<p>В результате я получил следующий график по использованию памяти:</p>
<p><img alt="export articles profiling" src="/media/2017/6/export_articles_without_iterator.png"/></p>
<p>Команда использует около 250Mb памяти, потому что при выполнении запроса <code>QuerySet</code> получает из БД сразу все статьи и
кэширует их в памяти, чтобы при последующем обращении к этому <code>QuerySet</code> дополнительные запросы не выполнялись.
Мы можем уменьшить объем используемой памяти, используя метод <code>iterator</code> класса <code>QuerySet</code>, который позволяет получать
результаты по одному, используя <a href="http://initd.org/psycopg/docs/cursor.html">server-side cursor</a>, и при этом он отключает
кэширование результатов в <code>QuerySet</code>:</p>
<p>```python</p>
<h1 id="_2">...</h1>
<p>for article in Article.objects.select_related('author').iterator():</p>
<h1 id="_3">...</h1>
<p>```</p>
<p>Запустив обновленный пример в профайлере я получил следующий результат:</p>
<p><img alt="export articles profiling" src="/media/2017/6/export_articles_with_iterator.png"/></p>
<p>Теперь команда использует всего 50Mb. Также приятным побочным эффектом является то, что при любом размере данных,
при использовании <code>iterator</code>, команда использует постоянный объем памяти. Вот графики для ~200Mb статей
(без <code>iterator</code> и с ним соответственно):</p>
<p><img alt="huge export articles profiling" src="/media/2017/6/export_articles_huge_before_and_after.png"/></p>
<h2 id="ispolzovanie-vneshnikh-kliuchei">Использование внешних ключей</h2>
<p>Теперь нам потребовалось добавить действие в админку статей для создания копии статьи:</p>
<p><code>python
def clone_article(modeladmin, request, queryset):
    if queryset.count() != 1:
        modeladmin.message_user(request, "You could clone only one article at a time.", level=messages.ERROR)
        return
    origin_article = queryset.first()
    cloned_article = Article(
        title="{} (COPY)".format(origin_article.title),
        content=origin_article.content,
        created_at=origin_article.created_at,
        author=origin_article.author,
        comments_on=origin_article.comments_on)
    cloned_article.save()
    cloned_article.tags = origin_article.tags.all()
    modeladmin.message_user(request, "Article successfully cloned", level=messages.SUCCESS)
clone_article.short_description = 'Clone article'</code></p>
<p>В логах можно увидеть следующие запросы к БД:</p>
<p><code>sql
(0.001) SELECT COUNT(*) AS "__count" FROM "blog_article" WHERE "blog_article"."id" IN (31582); args=(31582,)
(0.001) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" WHERE "blog_article"."id" IN (31582) ORDER BY "blog_article"."created_at" DESC, "blog_article"."id" DESC LIMIT 1; args=(31582,)
(0.000) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2156; args=(2156,)
(0.001) INSERT INTO "blog_article" ("title", "content", "created_at", "author_id", "comments_on") VALUES ('Explicabo maiores nobis cum vel fugit. (COPY)', ...</code></p>
<p>У нас почему-то запрашивается автор, хотя нам не нужны какие-либо данные об авторе, кроме его ID. Чтобы исправить это,
нужно обращаться к внешнему ключу напрямую, для получения id автора нужно использовать <code>origin_article.author_id</code>.
Теперь код клонирования статьи будет выглядеть следующим образом:</p>
<p><code>python
cloned_article = Article(
    title="{} (COPY)".format(origin_article.title),
    content=origin_article.content,
    created_at=origin_article.created_at,
    author_id=origin_article.author_id,
    comments_on=origin_article.comments_on)</code></p>
<p>И в логах больше нет запросов на получение информации об авторе.</p>
<h2 id="poluchenie-sviazannykh-obektov">Получение связанных объектов</h2>
<p>Наконец-то пришло время сделать наши статьи публично доступными, и начнем мы со страницы со списком статей. Реализуем
view, используя <code>ListView</code>:</p>
<p>```python
class ArticlesListView(ListView):</p>
<pre><code>template_name = 'blog/articles_list.html'
model = Article
context_object_name = 'articles'
paginate_by = 20
</code></pre>
<p>```</p>
<p>В шаблоне мы выводим информацию о статье, авторе и тегах:</p>
<p><code>django
&lt;article&gt;
    &lt;h2&gt;{{ article.title }}&lt;/h2&gt;
    &lt;time&gt;{{ article.created_at }}&lt;/time&gt;
    &lt;p&gt;Author: {{ article.author.username }}&lt;/p&gt;
    &lt;p&gt;Tags:
    {% for tag in article.tags.all %}
        {{ tag }}{% if not forloop.last %}, {% endif %}
    {% endfor %}
&lt;/article&gt;</code></p>
<p>DDT показывает при открытии списка статей 45 SQL запросов следующего вида:</p>
<p><code>sql
(0.002) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on" FROM "blog_article" LIMIT 20; args=()
(0.001) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2043; args=(2043,)
(0.001) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" = 20425; args=(20425,)
(0.000) SELECT "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_author" WHERE "blog_author"."id" = 2043; args=(2043,)
(0.001) SELECT "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" = 20426; args=(20426,)</code></p>
<p>Т.е. мы сначала получаем все статьи одним SQL запросом (с учетом пагинации) и затем для каждой из этих статей отдельно
запрашиваются автор и теги. Нам нужно заставить Django запросить все эти данные меньшим количеством запросов.</p>
<p>Начнем с получения авторов, для того, чтобы <code>QuerySet</code> получил заранее данные по определенным внешним ключам есть метод <code>select_related</code>. Обновим <code>queryset</code> в нашем view для использования этого метода:</p>
<p><code>python
queryset = Article.objects.select_related('author')</code></p>
<p>После этого DDT показывает уже 25 SQL запросов, т.к. получение информации об авторах и статьях теперь выполняется одним
SQL запросом с <code>JOIN</code>:</p>
<p><code>sql
(0.004) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on", "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_article" INNER JOIN "blog_author" ON ("blog_article"."author_id" = "blog_author"."id") LIMIT 21; args=()</code></p>
<p>Метод <code>select_related</code> работает только с внешними ключами в текущей модели, для того, чтобы уменьшить количество запросов
при получении множества связанных объектов (таких как теги в нашем примере), нужно использовать метод <code>prefetch_related</code>.
Опять обновим атрибут <code>queryset</code> у класса <code>AticlsListView</code>:</p>
<p><code>python
queryset = Article.objects.select_related('author').prefetch_related('tags')</code></p>
<p>И теперь DDT показывает всего 7 запросов. Если проигнорировать запросы, которые выполняет пагинатор и запросы, связанные
с сессией получаем всего 2 запроса для отображения списка статей:</p>
<p><code>sql
(0.002) SELECT "blog_article"."id", "blog_article"."title", "blog_article"."content", "blog_article"."created_at", "blog_article"."author_id", "blog_article"."comments_on", "blog_author"."id", "blog_author"."username", "blog_author"."email", "blog_author"."bio" FROM "blog_article" INNER JOIN "blog_author" ON ("blog_article"."author_id" = "blog_author"."id") LIMIT 20; args=()
(0.001) SELECT ("blog_article_tags"."article_id") AS "_prefetch_related_val_article_id", "blog_tag"."id", "blog_tag"."name" FROM "blog_tag" INNER JOIN "blog_article_tags" ON ("blog_tag"."id" = "blog_article_tags"."tag_id") WHERE "blog_article_tags"."article_id" IN (16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351); args=(16352, 16353, 16354, 16355, 16356, 16357, 16358, 16359, 16360, 16361, 16362, 16363, 16344, 16345, 16346, 16347, 16348, 16349, 16350, 16351)</code></p>
<blockquote>
<p>Используйте <code>select_related</code> для внешних ключей в текущей модели. Для получения M2M объектов и объектов из моделей
ссылающихся на текущую, используйте <code>prefetch_related</code>.</p>
<p>Также <code>prefetch_related</code> можно использовать для получения связанных объектов большей вложенности: </p>
<p><code>Tag.objects.all().prefetch_related('article_set__author')</code></p>
<p>Этот код запросит вместе с тегом также все статьи отмеченные тегом и всех авторов этих статей.</p>
</blockquote>
<h2 id="ogranichenie-polei-v-vyborkakh">Ограничение полей в выборках</h2>
<p>Если мы присмотримся получше к SQL запросам в предыдущем примере, мы увидим, что мы получаем больше полей, чем нам нужно.
В DDT можно посмотреть результаты запроса и убедиться в этом:</p>
<p><img alt="SQL query result for articles list" src="/media/2017/6/sql-queries-results.png"/></p>
<p>Мы получаем все поля автора и статьи, включая текст статьи огромного размера. Можно значительно
уменьшить объем передаваемых данных, используя метод defer, который позволяет отложить получение определенных полей.
В случае, если в коде все же произойдет обращение к такому полю, то Django сделает дополнительный запрос для его получения.
Добавим вызов метода <code>defer</code> в <code>queryset</code>:</p>
<p><code>python
queryset = Article.objects.select_related('author').prefetch_related('tags').defer('content', 'comments_on')</code></p>
<p>Теперь некоторые ненужные поля не запрашиваются и это уменьшило время обработки запроса, как нам показывает DDT
(до и после <code>defer</code> соответственно):</p>
<p><img alt="DDT - SQL speedup after defer" src="/media/2017/6/sql-speedup-defer.png"/></p>
<p>Мы все еще получаем множество полей автора, которые мы не используем. Проще было бы указать только те поля,
которые нам действительно нужны. Для этого есть метод <code>only</code>, передав которому названия полей, остальные поля будут отложены:</p>
<p><code>python
queryset = Article.objects.select_related('author').prefetch_related('tags').only(
    'title', 'created_at', 'author__username', 'tags__name')</code></p>
<p>В результате мы получаем только нужные данные, что можно посмотреть в DDT:</p>
<p><img alt="DDT - SQL after only" src="/media/2017/6/sql-after-only.png"/></p>
<p>Т.е. <code>defer</code> и <code>only</code> выполняют одну и ту же задачу, ограничения полей в выборках, различие только в то что:</p>
<ul>
<li><code>defer</code> откладывает получение полей переданных в качестве аргументов,</li>
<li><code>only</code> откладывает получение всех полей, кроме переданных.</li>
</ul>
<h2 id="indeksy-bd">Индексы БД</h2>
<p>Нам нужно сделать страницу автора, которая будет доступна по такому URL: <code>/authors/&lt;username&gt;</code>. Сделаем view
для этого:</p>
<p><code>python
def author_page_view(request, username):
    author = get_object_or_404(Author, username=username)
    return render(request, 'blog/author.html', context=dict(author=author))</code></p>
<p>Этот код работает достаточно быстро при небольшом объеме данных, но если объем значительный и продолжает расти, то
производительность будет только падать. Все дело в том, что для поиска по полю <code>username</code> СУБД приходится сканировать
всю таблицу до тех пор пока не найдет нужное значение. Есть вариант лучше - добавить на данное поле индекс, что позволит
СУБД искать гораздо эффективнее. Для добавления индекса нужно добавить аргумент <code>db_index=True</code> в объявление
поля <code>username</code>, а затем создать и применить миграции:</p>
<p>```python
class Author(models.Model):</p>
<pre><code>username = models.CharField(max_length=64, db_index=True)
# ...
</code></pre>
<p>```</p>
<p>Сравним производительность до и после добавления индекса на БД авторов размером в 100К.</p>
<p>Без индекса:</p>
<p><img alt="select by username without index" src="/media/2017/6/ddt-select-by-username-without-index.png"/></p>
<p>С индексом:</p>
<p><img alt="select by username with index" src="/media/2017/6/ddt-select-by-username-with-index.png"/></p>
<p>Запрос выполнился быстрее в 16 раз!</p>
<blockquote>
<p>Индексы полезны не только при фильтрации данных, но и при сортировке. Также многие СУБД позволяют делать индексы по
нескольким полям, что полезно, если вы фильтруете данные по набору полей. Советую изучить документацию к вашей СУБД,
чтобы узнать подробности.</p>
</blockquote>
<h2 id="lenqs-vs-qscount">len(qs) vs qs.count</h2>
<p>По какой-то причине, нам потребовалось вывести на странице со списком статей счетчик с количеством авторов. Обновим view:</p>
<p>```python
class ArticlesListView(ListView):</p>
<pre><code># ...

def get_context_data(self, **kwargs):
    context = super().get_context_data(**kwargs)
    context['authors_count'] = len(Author.objects.all())
    return context
</code></pre>
<p>```</p>
<p>Посмотрим какие SQL запросы генерирует этот код:</p>
<p><img alt="DDT - len(qs)" src="/media/2017/6/ddt-authors-len-queryset.png"/></p>
<p>На скриншоте мы видим, что запрашиваются все значения из таблицы авторов, соответственно подсчет количества происходит
уже в самом view. Конечно это не самый оптимальный вариант и нам было бы достаточно получить из БД одно число -
количество авторов. Для этого можно использовать метод <code>count</code>:</p>
<p><code>python
        context['authors_count'] = Author.objects.count()</code></p>
<p>Посмотрим результат в DDT:</p>
<p><img alt="DDT - len(qs)" src="/media/2017/6/ddt-authors-count.png"/></p>
<p>Теперь Django сгенерировал намного более оптимальный запрос для нашей задачи.</p>
<h2 id="count-vs-exists">count vs exists</h2>
<p>На странице автора нужно вывести ссылку на каталог статей этого автора, если у него есть статьи. Одним из решений будет
получить количество статей и сравнить равно ли количество 0, например так:</p>
<p><code>python
def author_page_view(request, username):
    author = get_object_or_404(Author, username=username)
    show_articles_link = (author.articles.count() &gt; 0)
    return render(
        request, 'blog/author.html',
        context=dict(author=author, show_articles_link=show_articles_link))</code></p>
<p>Но при большом количестве статей этот код будет работать медленно. Т.к. нам не нужно знать точное количество статей
у пользователя, то мы можем использовать метод <code>exists</code>, который проверяет, что в <code>QuertSet</code> есть хотя бы один результат:</p>
<p><code>python
    # ...
    show_articles_link = author.articles.exists()
    # ...</code></p>
<p>Сравниваем производительность при большом количестве статей (~10K):</p>
<p><img alt="DDT - exists vs count" src="/media/2017/6/ddt-exists-vs-count.png"/></p>
<p>Мы достигли цели запросом, который выполняется в 10 раз быстрее.</p>
<h2 id="lenivyi-queryset">Ленивый QuerySet</h2>
<p>Теперь нам захотелось, чтобы авторы конкурировали между собой, для этого мы добавим рейтинг топ-20 авторов по количеству
статей.</p>
<p><code>python
class ArticlesListView(ListView):
    # ...
    def get_context_data(self, **kwargs):
        # ...
        context['top_authors'] = list(
            Author.objects.order_by('-articles_count'))[:20]
        # ...</code></p>
<p>Здесь мы получаем список всех авторов, отсортированный по количеству статей, и берем первые 20 элементов этого списка.
<code>articles_count</code>, в нашем примере, это денормализованное поле, которое содержит количество статей у данного автора.
На реальном проекте, возможно вы захотели бы настроить сигналы, для актуализации этого поля.</p>
<p>Думаю уже сейчас понятно, что это не самый оптимальный вариант, это подтверждает и DDT:</p>
<p><img alt="DDT - get top authors slice" src="/media/2017/6/ddt-top-authors-list.png"/></p>
<p>Конечно нам нужно, чтобы ограничение выборки первыми 20-ю авторами происходило на стороне БД. Для этого нужно понять,
что <code>QuerySet</code> старается максимально отсрочить выполнение запроса к БД. Непосредственно запрос к БД осуществляется в
следующих случаях:</p>
<ul>
<li>итерация по QuerySet (например, <code>for obj in Model.objects.all():</code>),</li>
<li>slicing, если вы используете "нарезку" с определенным шагом (например, <code>Model.objects.all()[::2]</code>),</li>
<li>применение метода <code>len</code> (например, <code>len(Model.objects.all())</code>,</li>
<li>применение метода <code>list</code> (например, <code>list(Model.objects.all())</code>,</li>
<li>применение метода <code>bool</code> (например, <code>bool(Model.objects.all())</code>,</li>
<li>сериализация при помощи <a href="https://docs.python.org/3/library/pickle.html">pickle</a>.</li>
</ul>
<p>Т.е. вызвав <code>list</code> мы заставили <code>QuerySet</code> выполнить запрос к БД и вернуть нам список объектов, после чего уже к нему была
применена операция обрезки. Для того, чтобы ограничение выборки происходило в SQL запросе, нужно применить slicing
к самому <code>QuerySet</code>:</p>
<p><code>python
context['top_authors'] =\
    Author.objects.order_by('-articles_count')[:20]</code></p>
<p><img alt="DDT - get top authors slice on queryset" src="/media/2017/6/ddt-top-authors-qs-slice.png"/></p>
<p>Теперь размер выборки ограничивается в запросе: <code>...LIMIT 20</code>. Также видно, что отправка запроса
к БД была отложена до итерации по циклу в шаблоне.</p>
  </div>
</section>
        <footer id="contentinfo" class="body">
            (c) 2010-2017
        </footer><!-- /#contentinfo -->
</body>
</html>