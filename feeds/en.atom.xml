<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Tech blog by @dizballanze - en</title><link href="/" rel="alternate"></link><link href="http://dizballanze.com/feeds/en.atom.xml" rel="self"></link><id>/</id><updated>2018-05-24T11:27:00+03:00</updated><entry><title>Blazing fast tests in Django</title><link href="/django-blazing-fast-tests/" rel="alternate"></link><published>2018-05-24T11:27:00+03:00</published><updated>2018-05-24T11:27:00+03:00</updated><author><name>Admin</name></author><id>tag:None,2018-05-24:/django-blazing-fast-tests/</id><summary type="html">&lt;p&gt;Slow tests not only waste developers time on waiting but also make it difficult to follow TDD best practices
(such as red-green testing). If it needs minutes or even longer to run test suit, it leads to infrequent whole suit run.
Which in its turn leads to late bugs discovery â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;Slow tests not only waste developers time on waiting but also make it difficult to follow TDD best practices
(such as red-green testing). If it needs minutes or even longer to run test suit, it leads to infrequent whole suit run.
Which in its turn leads to late bugs discovery and fix.&lt;/p&gt;
&lt;p&gt;In this post, I'll tell how to speed up tests of your Django application. Also, I'll describe what kills your tests
performance. I will use simple tests suit as an example in this post. You can find it
&lt;a href="https://github.com/dizballanze/blazing-fast-django-tests-example/tree/initial"&gt;on GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="parallel-testing"&gt;Parallel testing&lt;/h2&gt;
&lt;p&gt;The most simple way to speed up tour tests without the need to make any code changes - run tests in parallel.
Django provides &lt;code&gt;--parallel&lt;/code&gt; option for running tests in parallel. This parameter also accepts an optional number of
processes. If this number wasn't provided it uses processes count equal to count of processor cores. For most of the
cases, this is optimal.&lt;/p&gt;
&lt;p&gt;Sequential running of tests from &lt;a href="https://github.com/dizballanze/blazing-fast-django-tests-example/tree/initial"&gt;the example&lt;/a&gt;
on my machine:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python manage.py test
...........
----------------------------------------------------------------------
Ran 11 tests in 8.012s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let's try to use &lt;code&gt;--parallel&lt;/code&gt; option:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python manage.py test --parallel
...........
----------------------------------------------------------------------
Ran 11 tests in 2.628s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see tests completed more than 3 times faster.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;It's worth noting that Django distributes execution of different test cases between different processes. Consequently,
if you have fewer test cases then processor cores Django will decrease the count of processes to match count of test cases.
In our example, we have only 3 test cases, so parallelism is limited to 3 processes. On real projects you probably
have hundreds or even thousands of test cases and this problem won't touch you.&lt;/p&gt;
&lt;p&gt;In some cases Django can't collect tracebacks on tests failures in parallel mode. In that case, you need to re-run
tests sequentially.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="use-weak-passwords-hashing-algorithm"&gt;Use weak passwords hashing algorithm&lt;/h2&gt;
&lt;p&gt;By default, Django uses a computationally difficult algorithm for passwords hashing. Regularly in new Django versions,
the hashing algorithm is reinforced. It needs for security, so intruder will need a lot of computing power to break passwords.&lt;/p&gt;
&lt;p&gt;We don't need such a strong algorithm in tests. We can go with something faster, such as MD5.
Let's add switching to MD5 for tests to &lt;code&gt;settings.py&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;

&lt;span class="n"&gt;TESTING&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s1"&gt;'test'&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;sys&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;argv&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;TESTING&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;PASSWORD_HASHERS&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;
        &lt;span class="s1"&gt;'django.contrib.auth.hashers.MD5PasswordHasher'&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    &lt;span class="p"&gt;]&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And run tests again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python manage.py test --parallel
...........
----------------------------------------------------------------------
Ran 11 tests in 0.564s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;4.65x times faster ðŸš€ I saw how this simple hack accelerated huge test suit by an order of magnitude.&lt;/p&gt;
&lt;h2 id="create-data-only-when-we-need-it"&gt;Create data only when we need it&lt;/h2&gt;
&lt;p&gt;A frequent mistake that slows down tests execution is to have a base test case with huge &lt;code&gt;setUp&lt;/code&gt; method that creates data
for the whole test suit. At first sight, it may seem convenient, but it kills your tests performance because
&lt;strong&gt;all&lt;/strong&gt; data are created before &lt;strong&gt;each&lt;/strong&gt; test no matter if you need them in this particular test or not.&lt;/p&gt;
&lt;p&gt;To fix this problem you need to simplify &lt;code&gt;setUp&lt;/code&gt; method. Ideally fully remove &lt;code&gt;setUp&lt;/code&gt; method from the base test case.
Test data should be created in particular test cases only when they are needed.&lt;/p&gt;
&lt;p&gt;I added &lt;a href="https://github.com/dizballanze/blazing-fast-django-tests-example/commit/45d89a2ee690e5077a7d957acd77aa4ceb1c41b8"&gt;corresponding changes&lt;/a&gt;
to our example. Let's see how this will affect tests running time:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python manage.py test --parallel
...........
----------------------------------------------------------------------
Ran 11 tests in 0.353s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;That's 60% more speed up.&lt;/p&gt;
&lt;h2 id="setuptestdata"&gt;setUpTestData&lt;/h2&gt;
&lt;p&gt;Base Django test case allows creating test data on the level of the test case instead of the test method. This allows
vastly accelerate tests execution. You need to move data creation to class method &lt;code&gt;setUpTestData&lt;/code&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Objects created in &lt;code&gt;setUpTestData&lt;/code&gt; shouldn't change while test running because it can lead to instability due to
not fully isolated tests.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I added changes to the example
&lt;a href="https://github.com/dizballanze/blazing-fast-django-tests-example/commit/5594cac4fd93c699b572f6946ce0a04ad96495f5"&gt;here&lt;/a&gt;.
Let's run tests again:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span&gt;&lt;/span&gt;# python manage.py test --parallel
...........
----------------------------------------------------------------------
Ran 11 tests in 0.349s
&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Seems that we don't get the significant speed up. Let's see what's happen if we add
&lt;a href="https://github.com/dizballanze/blazing-fast-django-tests-example/commit/c865ff7f72b04a0f72e8edfe3c523f1ee00b923e"&gt;some more tests&lt;/a&gt;.
Without &lt;code&gt;setUpTestData&lt;/code&gt; I get &lt;code&gt;0.536s&lt;/code&gt; duration and with &lt;code&gt;setUpTestData&lt;/code&gt; - &lt;code&gt;0.348s&lt;/code&gt;. As you can see with &lt;code&gt;setUpTestData&lt;/code&gt;
duration doesn't grow on adding new tests (besides duration of running the test itself) because test data aren't created
before each test.&lt;/p&gt;
&lt;h2 id="conclusion"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;It's desirable to pay attention to the speed of the tests from the very beginning of the development. Using simple methods
you can get very fast tests and get maximum benefit from automatic testing.&lt;/p&gt;
&lt;p&gt;live long and prosper ðŸ––&lt;/p&gt;</content></entry><entry><title>Pay attention to the code coverage report</title><link href="/test-coverage-report-in-use/" rel="alternate"></link><published>2018-04-29T12:28:00+03:00</published><updated>2018-04-29T12:28:00+03:00</updated><author><name>Admin</name></author><id>tag:None,2018-04-29:/test-coverage-report-in-use/</id><summary type="html">&lt;p&gt;If you are reading this post, you probably write unit-tests (and that's a good thing). Also, with high probability you
have heard about &lt;strong&gt;code coverage&lt;/strong&gt; metric. Which shows what code has run during testing. But how often do you actually
look at code coverage report? If not too often, when â€¦&lt;/p&gt;</summary><content type="html">&lt;p&gt;If you are reading this post, you probably write unit-tests (and that's a good thing). Also, with high probability you
have heard about &lt;strong&gt;code coverage&lt;/strong&gt; metric. Which shows what code has run during testing. But how often do you actually
look at code coverage report? If not too often, when this post is for you. I'll try to show you how code coverage
report opens a lot of useful data for developers, which in the end allows improving code quality.&lt;/p&gt;
&lt;h2 id="testing"&gt;Testing&lt;/h2&gt;
&lt;h3 id="code-without-tests"&gt;Code without tests&lt;/h3&gt;
&lt;p&gt;Most obvious benefit from code coverage report is an ability to detect which code isn't testing. Often this means that
you need to add a test(s) for this code to make sure that it works properly. And which is no less important, that it
will continue to work properly with further application development.&lt;/p&gt;
&lt;p&gt;Sometimes you can think, that one or the other code section is too simple and can't have any bugs. Accordingly,
you can avoid wasting time writing tests for it. In this moments you shouldn't forget, that code is changing and every
change may cause &lt;a href="https://en.wikipedia.org/wiki/Software_regression"&gt;regression&lt;/a&gt;. Each test can save you from hours of
debugging.&lt;/p&gt;
&lt;h3 id="running-of-not-expected-code-bug"&gt;Running of not expected code bug&lt;/h3&gt;
&lt;p&gt;Another case then a test passed but coverage report shows that code, that you expected to run, actually haven't run.&lt;/p&gt;
&lt;p&gt;This may occur due to a bug in a test. Another function is used instead of the right one, which returns the same result.
A bug like this leads to false sense of confidence, that code is working and regressions are tracked which isn't true.
Finally, it may cause deploying of broken code to the production and you'll have a hard time to debug this.&lt;/p&gt;
&lt;p&gt;The same result can be because of a bug in the code. For example, misconfigured web-application routing sends requests
to the wrong method, which occasionally returns expected response. This may lead to deploying the broken code to the
production and that would be hard to find this bug relying only on tests.&lt;/p&gt;
&lt;p&gt;Reviewing code coverage report before sending changes to the repository, you can find such kind of bugs and prevent
them before they cause damage, not to mention the time savings.&lt;/p&gt;
&lt;h2 id="dead-code_1"&gt;Dead code&lt;/h2&gt;
&lt;h3 id="unused-code"&gt;Unused code&lt;/h3&gt;
&lt;p&gt;In some cases, code coverage report can help you to find code which isn't used anymore. For example, private methods,
which aren't called anywhere.&lt;/p&gt;
&lt;p&gt;There is nothing pleasant about wasting time on reading a dead code and trying to understand why it is needed. Code
like this should be removed promptly. If you think you may need this code in future - still remove it. You can restore
it from version control system if needed.&lt;/p&gt;
&lt;h3 id="dead-code-in-tests"&gt;Dead code in tests&lt;/h3&gt;
&lt;p&gt;Another less obvious example of dead code - dead code in tests. You can have a test method in which you're looping over
a list of some objects and make asserts on each of them. If the list for some reason turns out to be empty, the test
will pass although none of the asserts actually occur. This kind of bugs is easy to discover with code coverage report
because loop body will be shown as not covered.&lt;/p&gt;
&lt;h2 id="conclusion_1"&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Code coverage report is a very important tool for a developer. You should look into the report after each change.
Ideally, this should be a part of your CI pipeline. If covered lines number was increased build should fail. Or at
least you should get a warning about this. This allows to avoid many bugs and increase overall code health.&lt;/p&gt;</content></entry></feed>